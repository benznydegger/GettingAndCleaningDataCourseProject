cachemean(1:4)
cachemean()
cachemean(2)
makeCacheMatrix <- function(x = matrix()) {
# Set the  matrix
inverse <- NULL
set_martix <- function(y) {
x <<- y
inverse <<- NULL
}
# get matrix
get_matrix <- function() x
# Cache the inverse
set_inversed_matrix <- function(solve_matrix) inverse <<- solve_matrix
get_inversed_matix <- function() inverse
# Returned list
list(set_martix = set_martix, get_matrix = get_matrix, set_inversed_matrix = set_inversed_matrix, get_inversed_matix = get_inversed_matix)
}
cacheSolve <- function(x, ...) {
inverse <- x$get_inversed_matix()
if(!is.null(inverse)) {
message("getting cached data")
return(inverse)
}
data <- x$get_matrix()
inverse <- solve(data)
x$set_inversed_matrix(inverse)
inverse
}
cacheSolve()
cacheSolve(2)
cacheSolve(2,)
makeCacheMatrix <- function(matrix_in = matrix()) {
if(det(matrix_in) == 0) {
message('Matrix is not invertible')
}else{
dimension <- dim(matrix_in)
if(dimension[1] != dimension[2]){
message('Matrix must be a square matrix')
}else{
if(!exists("matrix_inv", inherits = TRUE)){
matrix_inv <<- matrix()
}
if(!exists("matrix_save", inherits = TRUE)){
matrix_save <<- matrix()
}
matrix_save <<- matrix_in
matrix_inv  <<- solve(matrix_in)
x <- matrix_in
x
}
}
}
cacheSolve <- function(matrix_in, ...) {
if(det(matrix_in) == 0) {
message('Matrix is not invertible')
}else{
dimension <- dim(matrix_in)
if(dimension[1] != dimension[2]){
message('Matrix must be a square matrix')
}else{
if(!exists("matrix_inv", inherits = TRUE)){
x <- solve(matrix_in)
}else{
if(identical(matrix_in, matrix_save) == FALSE){
x <- solve(matrix_in)
}else{
x <- matrix_inv
}
}
x
}
}
}
my_matrix <- makeCacheMatrix(matrix(1:4, 2, 2))
cacheSolve(my_matrix)
my_matrix
my_matrix$set(matrix(c(2, 2, 1, 4), 2, 2))
my_matrix <- makeCacheMatrix(matrix(c(2, 2, 1, 4), 2, 2))
cacheSolve(my_matrix)
cacheSolve(my_matrix)
cacheSolve(my_matrix)
makeCacheMatrix(matrix(1:4, 2, 2))
my_matrix <- makeCacheMatrix(matrix(c(2, 2, 1, 4), 2, 2))
makeCacheMatrix(matrix(1:4, 2, 2))
my_matrix <- makeCacheMatrix(matrix(c(2, 2, 1, 4), 2, 2))
my_matrix <- makeCacheMatrix(matrix(c(2, 1, 1, 4), 2, 2))
my_matrix
makeCacheMatrix(matrix(1:4, 2, 1))
my_matrix <- makeCacheMatrix(matrix(c(2, 1, 1, 4), 2, 2))
cacheSolve(my_matrix)
cacheSolve <- function(matrix_in, ...) {
if(det(matrix_in) == 0) {
message('Matrix is not invertible')
}else{
dimension <- dim(matrix_in)
if(dimension[1] != dimension[2]){
message('Matrix must be a square matrix')
}else{
if(!exists("matrix_inv", inherits = TRUE)){
x <- solve(matrix_in)
}else{
if(identical(matrix_in, matrix_save) == FALSE){
x <- solve(matrix_in)
}else{
x <- matrix_inv
message("cached data")
}
}
x
}
}
}
my_matrix <- makeCacheMatrix(matrix(c(2, 2, 1, 4), 2, 2))
cacheSolve(my_matrix)
str(cacheSolve)
cacheSolve(matrix(1:4, 2, 2))
cacheSolve(my_matrix)
str(lm)
str(lm)
str(ls)
x <- rnorm(10, 2, 4)
summary(x)
str(x)
x
f <- gl(40, 10)
f
f <- gl(40, 3)
f
str(f)
summary(f)
library(datasets)
head(airquality)
str(airquality)
m <- matrix(rnorm(100), 10, 10)
m
str(m)
m[, 1]
s <- split(airquality, airquality$Month)
s
s <- split(airquality, airquality$Month)
str(s)
str(s[,1])
class(s)
str(s[[1]])
str(s[[9]])
str(s[[5]])
str(s)
str(s[[5]])
str(s$9)
str(s$5)
str(s$Ozone)
s$Ozone
s
str(s[`9`])
str(s[[`9`])
str(s[[`9`]]
)
s[[`9`]]
s[[S`9`]]
s[[s$`5`]]
s$`5`
s$`9`
m <- matrix(rnorm(10), 10, 10)
m
m <- matrix(rnorm(100), 10, 10)
m
m <- matrix(rnorm(5), 10, 10)
m
m <- matrix(rnorm(10), 10, 10)
m
m <- matrix(rnorm(100), 10, 10)
m
m <- matrix(rnorm(1), 10, 10)
m
x <- rnorm(10)
x
x <- rnorm(10, 20, 2)
x
summary(x)
set.seed(1)
rnorm(5)
rnorm(5)
set.seed(1)
rnorm(5)
rpois(10, 1)
rpois(10, 2)
rpois(10, 20)
ppois(2, 2)
ppois(4, 2)
ppois(6, 2)
set.seed(20)
x <- rnorm(100)
e <- rnorm(100, 0, 2)
y <- 0.5 + 2 * x + e
summary(y)
plot(x,y)
plot(x, y)
hist(Nile)
Nile
par(mar=rep(2,4))
hist(Nile)
plot(x, y)
set.seed(1)
z <- rpois(5, 2)
class(z)
summary(z)
str(z)
z
?set.seed
?ppois
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
system.time({
z <- quote(y <- x * 10)
z
})
Rprof(z <- quote(y <- x * 10))
Rprof()
system.time({
n <- 1000
r <- numeric(n)
for (i in 1:n) {
x <- rnorm(n)
r[i] <- mean(x)
}
})
system.time({
n <- 1000
r <- numeric(n)
for (i in 1:n) {
x <- rnorm(n)
r[i] <- mean(x)
}
})
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
y <- 100
x1 <- 55
x2 <- 99
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
?lm
fit
Rprof(NULL)
Rprof()
fit
summaryRprof()'
fit
c
Q
''
summaryRprof()
summaryRprof(fit)
summaryRprof()
?seed
?set.seed
ucscDb <- dbConnect(MySQL(),user="genome",
host="genome-mysql.cse.ucsc.edu")
library(rhdf5)
created = h5createFile("example.h5")
created
created = h5createGroup("example.h5","foo")
created = h5createGroup("example.h5","baa")
created = h5createGroup("example.h5","foo/baa")
A = matrix(1:10,nr=5,nc=2)
h5write(A, "Example.h5","foo/A")
B= array(seq(0.1,2.0,by=0.1),dim=c(5,2,2))
att(B, "scale") <- "liter"
attr(B, "scale") <- "liter"
h5write(B, "example.h5","foo/foobaa/B")
h5write(A, "example.h5","foo/A")
created = h5createGroup("example.h5","foo/foobaa")
h5write(B, "example.h5","foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5L,seq(0,1,length.out=5),
c("ab","cde","fghi","a","s"), stringsAsFactors=FALSE)
h5write(df, "example.h5","df")
h5ls("example.h5")
readA = h5read("example.h5","foo/A")
readB = h5read("example.h5","foo/foobaa/B")
readdf = h5read("example.h5","df")
readA
h5write(c(12,13,114),"example.h5",foo/A",index=list(1:3,1))
h5read("example.h5","foo/A")
h5write(c(12,13,114),"example.h5",foo/A",index=list(1:3,1))
)
"
h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1))
h5read("example.h5","foo/A")
library("RMySQL")
ucscDb <- dbConnect(MySQL(),user="genome",
host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb,"show databases;"); dbDisconnect(ucscDb);
ucscDb <- dbConnect(MySQL(),user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
hg19 <- dbConnect(MySQL(),user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
library(XML)
url <- "http://www.lohse.ch/bio_e.html"
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//h1]", xmlValue)
xpathSApply(html, "//h1", xmlValue)
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(httr); html2 = GET(url)
content2 = content(html2,as="text")
parsedHtml = htmlParse(contenet2,asText=TRUE)
parsedHtml = htmlParse(content2,asText=TRUE)
xpathSApply(parseHtml, "//title", xmlValue)
library(XML)
xpathSApply(parseHtml, "//title", xmlValue)
parsedHtml = htmlParse(content2,asText=TRUE)
xpathSApply(parseHtml, "//title", xmlValue)
xpathSApply(parsedHtml, "//title", xmlValue)
pg1 = GET("https://accounts.google.com/signin/v2/identifier?continue=https%3A%2F%2Fmail.google.com%2Fmail%2F&service=mail&sacu=1&rip=1&flowName=GlifWebSignIn&flowEntry=ServiceLogin")
pg1
pg2 = GET("https://accounts.google.com/signin/v2/identifier?continue=https%3A%2F%2Fmail.google.com%2Fmail%2F&service=mail&sacu=1&rip=1&flowName=GlifWebSignIn&flowEntry=ServiceLogin",
authenticate("benz.nydegger@gmail.com","Kari77Romang"))
pg2
pg2 = GET("http://10.0.0.145:8081/",
authenticate("admin","AkQR3jl6K"))
)
pg2 = GET("http://10.0.0.145:8081",
authenticate("admin","AkQR3jl6K"))
google = handle("http://google.com")
pg1 = GET(handle=google,path="/")
pg1
pg2 - GET(handle=google,path='search")
->pg2
= pg2
)
""
"
''
'
pg2 = GET(handle=google,path="search")
pg2
pg3 = GET("https://github.com/login")
authenticate("benz.nydegger@gmail.com","Aju7Yt!jlX"))
pg3 = GET("https://github.com/login"
authenticate("benz.nydegger@gmail.com","Aju7Yt!jlX"))
pg3 = GET("https://github.com/login"
authenticate("benz.nydegger\@gmail.com","Aju7Yt!jlX"))
pg3
library(httr)
oauth_endpoints("github")
quizapp1 = oauth_app("github",
key="990f86acc8d7f3fedb95",
secret="fddab0f85b8825a58b3c9fac99e6113a7c692d3d")
github_token <- oauth2.0_token(oauth_endpoints("github"), quizapp1)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
req <- GET("https://github.com/benznydegger/quizapp1", gtoken)
stop_for_status(req)
content(req)
library(httr)
oauth_endpoints("github")
quizapp1 = oauth_app("github",
key="990f86acc8d7f3fedb95",
secret="fddab0f85b8825a58b3c9fac99e6113a7c692d3d")
github_token <- oauth1.0_token(oauth_endpoints("github"), quizapp1)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
dim(req)
str(req)
summary(req)
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
jsonData$name
jsonData$name$datasharing
jsonData$name[14]
jsonData$name$datasharing
jsonData$name[datasharing]
jsonData$name["datasharing"]
jsonData$id
jsonData$id$1
names(jsonData$name)
jsonData$id
names(jsonData$id)
names(jsonData)
names(jsonData$name)
names(req)
req$date
content(req)
content(req$date)
content(req[[30]])
req[[30]]
req[30]
qq <-content(req)
class(qq)
qq[[30]]
## --------------------------------
## CourseraCourse: DataScience - 3. Getting and Cleaning Data Course Project
## --------------------------------
## This is a script created within a course work assignement
## File Name: run_analysis.R
## Student/Author: Benz Nydegger
## Date: 20-May-2018
## Input Data: UCI HAR Dataset
## Output Data: average_per_activity_and_subject.txt
## More information available in the README.md and CodeBook.md
#------------------------------------------------------------
#1. Merges the training and the test sets to create one data set.
#------------------------------------------------------------
# Set working directory
setwd("C:/Users/GuyManuelBendichtNyd/Desktop/DataScience/JohnHoppkins/3.Getting and Cleaning Data/Week4/Assignement/UCI HAR Dataset")
# Read training & test data
testset <- read.table("test/X_test.txt")
trainset <- read.table("train/X_train.txt")
#testset <- read.table("test/X_test.txt", colClasses= "character")
#trainset <- read.table("train/X_train.txt", colClasses= "character")
# Create one data set from both tables
testandtraindataset <- rbind(testset, trainset)
#------------------------------------------------------------
#2. Extracts only the measurements on the mean and standard deviation for each measurement.
#------------------------------------------------------------
# Lable Columns
features <- readLines("features.txt")
# Find mean() & std() deviation entries
features <- grep("mean\\(\\)|std\\(\\)",features, value=TRUE)
# Get feature number for dataframe column extraction
featurestring <- strsplit(features," ")
firstElement <- function(x){x[1]}
featurenumber <- sapply(featurestring,firstElement)
featurenumber <- as.integer(featurenumber)
# Extract data for the mean & standard deviation measurments
meanandstandarddeviation <- testandtraindataset[,featurenumber]
#------------------------------------------------------------
#3. Uses descriptive activity names to name the activities in the data set
#------------------------------------------------------------
# Activity Lables
activitylables <- readLines("activity_labels.txt")
# Get Activity Vector
allactivities <- c(as.numeric(readLines("test/y_test.txt")), as.numeric(readLines("train/y_train.txt")))
#allactivities <- as.character(c(as.integer(readLines("test/y_test.txt")), as.integer(readLines("train/y_train.txt"))))
# Resolve activity number to lable
allactivities <- gsub("1", activitylables[1], allactivities)
allactivities <- gsub("2", activitylables[2], allactivities)
allactivities <- gsub("3", activitylables[3], allactivities)
allactivities <- gsub("4", activitylables[4], allactivities)
allactivities <- gsub("5", activitylables[5], allactivities)
allactivities <- gsub("6", activitylables[6], allactivities)
# Add activity column to the left
meanandstandarddeviation <- cbind(activity=allactivities,meanandstandarddeviation)
#------------------------------------------------------------
#4. Appropriately labels the data set with descriptive variable names.
#------------------------------------------------------------
secondelement <- function(x){x[2]}
features <- sapply(featurestring,secondelement)
features <- gsub("^t", "time", features)
features <- gsub("^f", "frequency", features)
features <- gsub("Acc", "acceleration", features)
features <- gsub("Gyro", "gyroscope", features)
features <- gsub("std","standarddeviation", features)
features <- gsub("Mag","magnitude", features)
features <- gsub("-","", features)
features <- gsub("\\(\\)","", features)
features <- gsub("X$", "_X", features)
features <- gsub("Y$", "_Y", features)
features <- gsub("Z$", "_Z", features)
features <- tolower(features)
meanandstandarddeviation <- setNames(meanandstandarddeviation, c("activity", features))
## check tidiness
head(rownames(meanandstandarddeviation))
tail(rownames(meanandstandarddeviation))
colnames(meanandstandarddeviation)[1]
colnames(meanandstandarddeviation)[2]
#------------------------------------------------------------
#5. From the data set in step 4, creates a second, independent tidy data set with the
#	average of each variable for each activity and each subject.
#------------------------------------------------------------
# Create Subject Vector
subjects <- c(as.numeric(readLines("test/subject_test.txt")), as.numeric(readLines("train/subject_train.txt")))
subjects <- as.factor(subjects)
# Add subject column to the left
meanandstandarddeviation <- cbind(subject=subjects,meanandstandarddeviation)
library(dplyr)
library(datasets)
data(meanandstandarddeviation)
# with  group
solution <- meanandstandarddeviation %>%
group_by(subject,activity) %>% summarise_all(mean)
solution
solution2 <- meanandstandarddeviation %>%
group_by(activity,subject) %>% summarise_all(mean)
solution2
typeof(testset)
testset
class(testset)
class(features)
typeof(features)
write.table(solution,"filename.txt",sep="\t",row.names=FALSE)
solution
write.table(solution,"filename.csv",sep=",",row.names=FALSE)
